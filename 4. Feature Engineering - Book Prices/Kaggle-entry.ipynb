{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c08e9347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import zscore\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Title', 'Author', 'Edition', 'Reviews', 'Ratings', 'Synopsis', 'Genre',\n",
      "       'BookCategory', 'Price'],\n",
      "      dtype='object')\n",
      "(5699, 9)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"Data_Train.xlsx\")\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Title', 'Author', 'Edition', 'Reviews', 'Ratings',\n",
      "       'Synopsis', 'Genre', 'BookCategory'],\n",
      "      dtype='object')\n",
      "(537, 9)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_excel(\"test.xlsx\")\n",
    "print(df_test.columns)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Detect Outliers</h4>\n",
    "Identify outliers using the Z-score method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_scores = pd.DataFrame(zscore(df['Price']), columns=['Price'])\n",
    "\n",
    "# threshold = 2\n",
    "# outliers = df[(z_scores.abs() > threshold).any(axis=1)]\n",
    "\n",
    "# print(\"Outlier records:\")\n",
    "# print(outliers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_with_outlier = df.copy()\n",
    "# df = df[(z_scores.abs() < threshold).all(axis=1)].reset_index(drop=True)\n",
    "\n",
    "# print(\"DataFrame without outliers:\")\n",
    "# print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Combine Datasets</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Dataset: df[5699:]\n",
    "df_train = df.copy()\n",
    "df_test.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "df = pd.concat([df_train, df_test], sort=False)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Delete Unnecessary Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1b98557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Edition</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Genre</th>\n",
       "      <th>BookCategory</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Prisoner's Gold (The Hunters 3)</td>\n",
       "      <td>Chris Kuzneski</td>\n",
       "      <td>Paperback,– 10 Mar 2016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "      <td>THE HUNTERS return in their third brilliant no...</td>\n",
       "      <td>Action &amp; Adventure (Books)</td>\n",
       "      <td>Action &amp; Adventure</td>\n",
       "      <td>220.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guru Dutt: A Tragedy in Three Acts</td>\n",
       "      <td>Arun Khopkar</td>\n",
       "      <td>Paperback,– 7 Nov 2012</td>\n",
       "      <td>3.9</td>\n",
       "      <td>14</td>\n",
       "      <td>A layered portrait of a troubled genius for wh...</td>\n",
       "      <td>Cinema &amp; Broadcast (Books)</td>\n",
       "      <td>Biographies, Diaries &amp; True Accounts</td>\n",
       "      <td>202.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title          Author   \n",
       "0  The Prisoner's Gold (The Hunters 3)  Chris Kuzneski  \\\n",
       "1   Guru Dutt: A Tragedy in Three Acts    Arun Khopkar   \n",
       "\n",
       "                   Edition  Reviews  Ratings   \n",
       "0  Paperback,– 10 Mar 2016      4.0        8  \\\n",
       "1   Paperback,– 7 Nov 2012      3.9       14   \n",
       "\n",
       "                                            Synopsis   \n",
       "0  THE HUNTERS return in their third brilliant no...  \\\n",
       "1  A layered portrait of a troubled genius for wh...   \n",
       "\n",
       "                        Genre                          BookCategory   Price  \n",
       "0  Action & Adventure (Books)                    Action & Adventure  220.00  \n",
       "1  Cinema & Broadcast (Books)  Biographies, Diaries & True Accounts  202.93  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Reviews'] = df['Reviews'].str[:3].astype(float)\n",
    "df['Ratings'] = df['Ratings'].str.extract('(\\\\d+)').astype(int)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Authors: 3678\n",
      "Unique Titles: 5567\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Authors: \" + str(df['Author'].nunique()))\n",
    "print(\"Unique Titles: \" + str(df['Title'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Edition</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Genre</th>\n",
       "      <th>BookCategory</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Prisoner's Gold (The Hunters 3)</td>\n",
       "      <td>chriskuzneski</td>\n",
       "      <td>Paperback,– 10 Mar 2016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "      <td>THE HUNTERS return in their third brilliant no...</td>\n",
       "      <td>Action &amp; Adventure (Books)</td>\n",
       "      <td>Action &amp; Adventure</td>\n",
       "      <td>220.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guru Dutt: A Tragedy in Three Acts</td>\n",
       "      <td>arunkhopkar</td>\n",
       "      <td>Paperback,– 7 Nov 2012</td>\n",
       "      <td>3.9</td>\n",
       "      <td>14</td>\n",
       "      <td>A layered portrait of a troubled genius for wh...</td>\n",
       "      <td>Cinema &amp; Broadcast (Books)</td>\n",
       "      <td>Biographies, Diaries &amp; True Accounts</td>\n",
       "      <td>202.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title         Author   \n",
       "0  The Prisoner's Gold (The Hunters 3)  chriskuzneski  \\\n",
       "1   Guru Dutt: A Tragedy in Three Acts    arunkhopkar   \n",
       "\n",
       "                   Edition  Reviews  Ratings   \n",
       "0  Paperback,– 10 Mar 2016      4.0        8  \\\n",
       "1   Paperback,– 7 Nov 2012      3.9       14   \n",
       "\n",
       "                                            Synopsis   \n",
       "0  THE HUNTERS return in their third brilliant no...  \\\n",
       "1  A layered portrait of a troubled genius for wh...   \n",
       "\n",
       "                        Genre                          BookCategory   Price  \n",
       "0  Action & Adventure (Books)                    Action & Adventure  220.00  \n",
       "1  Cinema & Broadcast (Books)  Biographies, Diaries & True Accounts  202.93  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['Title'] = df['Title'].str.replace('[^a-zA-Z0-9]', '', regex=True).str.lower()\n",
    "df['Author'] = df['Author'].str.replace('[^a-zA-Z0-9]', '', regex=True).str.lower()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1eab6a",
   "metadata": {},
   "source": [
    "\n",
    "## Feature Engineering\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Genrate new features</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Paperback', 'Hardcover', 'Mass Market Paperback', 'Sheet music',\n",
       "       'Flexibound', 'Plastic Comb', 'Loose Leaf', 'Tankobon Softcover',\n",
       "       'Perfect Paperback', 'Board book', 'Cards', 'Spiral-bound',\n",
       "       '(Kannada)', 'Product Bundle', 'Library Binding', '(German)',\n",
       "       'Leather Bound', '(French)', '(Spanish)'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CoverType'] = df['Edition'].str.split(',').str[0]\n",
    "df['CoverType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Year'] = df['Edition'].str.extract(r'(\\d{4})').fillna(2019).astype(int)\n",
    "df['Year'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BookAge'] = 2020 - df['Year']\n",
    "df['BookAge'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3652      1.0\n",
       "1024      1.0\n",
       "467       1.0\n",
       "2848      1.0\n",
       "767       2.0\n",
       "        ...  \n",
       "2764    282.0\n",
       "2769    300.0\n",
       "5164    389.5\n",
       "3664    414.0\n",
       "3764    468.0\n",
       "Name: ReviewImpact, Length: 6236, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ReviewImpact'] = df['BookAge'] * df['Reviews']\n",
    "df['ReviewImpact'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3414       0.030303\n",
       "299        0.034483\n",
       "1855       0.038462\n",
       "3908       0.038462\n",
       "3267       0.041667\n",
       "           ...     \n",
       "3960    1516.000000\n",
       "968     1630.000000\n",
       "962     3444.000000\n",
       "3148    3608.000000\n",
       "933     3608.000000\n",
       "Name: RatingImpact, Length: 6236, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RatingImpact'] = df['Reviews'].astype(int) * df['Ratings'].astype(int) / df['BookAge'].astype(int)\n",
    "df['RatingImpact'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Utilize NLP to extract Keywords and Sentiment</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Synopsis'] = df['Synopsis'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Polarity\"] =  df['Synopsis'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "df[\"Subjectivity\"] = df['Synopsis'].apply(lambda x: TextBlob(x).sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Function to extract keywords from Synopsis using SpaCy\n",
    "def extract_keywords(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc if not token.is_stop and token.is_alpha]\n",
    "\n",
    "df['Keywords'] = df['Title'].apply(extract_keywords)\n",
    "# df['Keywords'] = df['Keywords'].apply(lambda x: ' '.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Book', 385), ('Guide', 224), ('Classics', 188), ('Edition', 185), ('English', 185), ('India', 183), ('World', 166), ('Vol', 140), ('Life', 134), ('Penguin', 125), ('Story', 125), ('Series', 124), ('Novel', 118), ('Man', 117), ('Complete', 109), ('Art', 95), ('New', 94), ('Dictionary', 92), ('Love', 91), ('Graphic', 89), ('Adventures', 88), ('Oxford', 86), ('Indian', 84), ('Modern', 81), ('Stories', 77), ('History', 73), ('Data', 68), ('Learning', 68), ('Grammar', 65), ('Asterix', 64), ('Volume', 63), ('Big', 62), ('Vintage', 61), ('Secret', 61), ('Great', 60), ('Design', 58), ('Novels', 58), ('Autobiography', 56), ('Books', 55), ('Course', 55), ('Practice', 54), ('Easy', 54), ('CD', 54), ('Girl', 51), ('Trilogy', 51), ('Learn', 50), ('Programming', 50), ('Way', 50), ('Tintin', 49), ('Cambridge', 49), ('Death', 48), ('Science', 48), ('War', 48), ('Words', 48), ('Game', 48), ('series', 46), ('Journey', 46), ('Step', 45), ('Fire', 45), ('Library', 45), ('Grade', 44), ('Mind', 44), ('Piano', 43), ('Exam', 43), ('Black', 43), ('Reference', 43), ('Level', 43), ('Language', 42), ('Night', 42), ('Little', 42), ('Time', 42), ('Key', 41), ('Short', 40), ('Calvin', 40), ('Hobbes', 40), ('Best', 40), ('Business', 39), ('Lost', 39), ('Day', 39), ('Magic', 39), ('Things', 38), ('Power', 38), ('Red', 38), ('Python', 37), ('Secrets', 36), ('Music', 36), ('True', 36), ('Trinity', 36), ('Introduction', 36), ('Comics', 35), ('Collection', 35), ('Theory', 35), ('Omnibus', 35), ('College', 35), ('Dragon', 35), ('Biography', 34), ('Cat', 34), ('Dark', 34), ('Know', 34), ('Cricket', 34), ('Women', 34), ('Ultimate', 34), ('Album', 34), ('Training', 34), ('Poirot', 33), ('Set', 33), ('House', 33), ('Colouring', 33), ('International', 33), ('Days', 33), ('Collins', 33), ('Questions', 33), ('Drawing', 32), ('Classic', 32), ('Inside', 32), ('Computer', 32), ('C', 31), ('Digital', 31), ('Good', 31), ('Years', 30), ('Making', 30), ('Men', 30), ('Essential', 30), ('Times', 30), ('Ice', 30), ('Jack', 30), ('Java', 29), ('Test', 29), ('Guitar', 29), ('Creative', 29), ('Machine', 28), ('End', 28), ('Tales', 28), ('People', 28), ('Illustrated', 28), ('Answers', 28), ('London', 27), ('Batman', 27), ('IELTS', 27), ('Ideas', 27), ('Self', 26), ('Dover', 26), ('Greatest', 26), ('Blue', 26), ('Film', 26), ('Study', 26), ('Practical', 26), ('Campfire', 26), ('Quick', 26), ('Reads', 25), ('Visual', 25), ('Official', 25), ('Read', 25), ('Body', 25), ('Pack', 25), ('High', 25), ('Writing', 25), ('Like', 25), ('Basic', 25), ('Harry', 25), ('Games', 25), ('Second', 24), ('Beginner', 24), ('Lessons', 24), ('French', 24), ('Archie', 24), ('Dog', 24), ('Readers', 24), ('Success', 24), ('Truth', 24), ('Techniques', 24), ('Murder', 24), ('Blood', 23), ('Song', 23), ('Human', 23), ('Century', 23), ('Photography', 22), ('Economy', 22), ('Year', 22), ('Ladybird', 22), ('Performance', 22), ('Architecture', 22), ('Chess', 22), ('Work', 22), ('Brain', 22), ('King', 21), ('Political', 21), ('Dead', 21), ('Teach', 21), ('Pieces', 21), ('Assassin', 21), ('Skills', 21), ('Revised', 21), ('City', 21), ('Right', 21), ('James', 21), ('Stilton', 21), ('Student', 21), ('Sherlock', 21), ('Tell', 21)]\n",
      "['Book', 'Guide', 'Classics', 'Edition', 'English', 'India', 'World', 'Vol', 'Life', 'Penguin', 'Story', 'Series', 'Novel', 'Man', 'Complete', 'Art', 'New', 'Dictionary', 'Love', 'Graphic', 'Adventures', 'Oxford', 'Indian', 'Modern', 'Stories', 'History', 'Data', 'Learning', 'Grammar', 'Asterix', 'Volume', 'Big', 'Vintage', 'Secret', 'Great', 'Design', 'Novels', 'Autobiography', 'Books', 'Course', 'Practice', 'Easy', 'CD', 'Girl', 'Trilogy', 'Learn', 'Programming', 'Way', 'Tintin', 'Cambridge', 'Death', 'Science', 'War', 'Words', 'Game', 'series', 'Journey', 'Step', 'Fire', 'Library', 'Grade', 'Mind', 'Piano', 'Exam', 'Black', 'Reference', 'Level', 'Language', 'Night', 'Little', 'Time', 'Key', 'Short', 'Calvin', 'Hobbes', 'Best', 'Business', 'Lost', 'Day', 'Magic', 'Things', 'Power', 'Red', 'Python', 'Secrets', 'Music', 'True', 'Trinity', 'Introduction', 'Comics', 'Collection', 'Theory', 'Omnibus', 'College', 'Dragon', 'Biography', 'Cat', 'Dark', 'Know', 'Cricket', 'Women', 'Ultimate', 'Album', 'Training', 'Poirot', 'Set', 'House', 'Colouring', 'International', 'Days', 'Collins', 'Questions', 'Drawing', 'Classic', 'Inside', 'Computer', 'C', 'Digital', 'Good', 'Years', 'Making', 'Men', 'Essential', 'Times', 'Ice', 'Jack', 'Java', 'Test', 'Guitar', 'Creative', 'Machine', 'End', 'Tales', 'People', 'Illustrated', 'Answers', 'London', 'Batman', 'IELTS', 'Ideas', 'Self', 'Dover', 'Greatest', 'Blue', 'Film', 'Study', 'Practical', 'Campfire', 'Quick', 'Reads', 'Visual', 'Official', 'Read', 'Body', 'Pack', 'High', 'Writing', 'Like', 'Basic', 'Harry', 'Games', 'Second', 'Beginner', 'Lessons', 'French', 'Archie', 'Dog', 'Readers', 'Success', 'Truth', 'Techniques', 'Murder', 'Blood', 'Song', 'Human', 'Century', 'Photography', 'Economy', 'Year', 'Ladybird', 'Performance', 'Architecture', 'Chess', 'Work', 'Brain', 'King', 'Political', 'Dead', 'Teach', 'Pieces', 'Assassin', 'Skills', 'Revised', 'City', 'Right', 'James', 'Stilton', 'Student', 'Sherlock', 'Tell']\n",
      "      Keyword\n",
      "0        Book\n",
      "1       Guide\n",
      "2    Classics\n",
      "3     Edition\n",
      "4     English\n",
      "..        ...\n",
      "195     James\n",
      "196   Stilton\n",
      "197   Student\n",
      "198  Sherlock\n",
      "199      Tell\n",
      "\n",
      "[200 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_keywords = [keyword for sublist in df['Keywords'] for keyword in sublist]\n",
    "keyword_counts = Counter(all_keywords)\n",
    "top_keywords = keyword_counts.most_common(200)\n",
    "\n",
    "print(top_keywords)\n",
    "\n",
    "for i in range(len(top_keywords)): \n",
    "    top_keywords[i] = top_keywords[i][0]\n",
    "    \n",
    "print(top_keywords)\n",
    "top_keywords_df = pd.DataFrame(top_keywords, columns=['Keyword'])\n",
    "print(top_keywords_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6778dea",
   "metadata": {},
   "source": [
    "## Feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ecd88ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TF-IDF Vectorizer for Keywords\n",
    "df['Keywords'] = df['Keywords'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "tfidf_vectorizer_title = TfidfVectorizer()\n",
    "tfidf_matrix_title = tfidf_vectorizer_title.fit_transform(df['Keywords'])\n",
    "\n",
    "n_components = 50\n",
    "pca = PCA(n_components=n_components)\n",
    "tfidf_matrix_title = pca.fit_transform(tfidf_matrix_title.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Function to extract keywords from Synopsis using SpaCy\n",
    "def extract_keywords(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc if not token.is_stop and token.is_alpha]\n",
    "\n",
    "df['SynopsisKeywords'] = df['Synopsis'].apply(extract_keywords)\n",
    "backup = df['SynopsisKeywords'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       hunters return brilliant novel sunday times be...\n",
       "1       layered portrait troubled genius art merely th...\n",
       "2       time men live common power awe condition calle...\n",
       "3       handful grain found pocket murdered businessma...\n",
       "4       seven decades life thrilling world unrivalled ...\n",
       "                              ...                        \n",
       "6231    brilliant sarah knight funny mark watson exhil...\n",
       "6232    gripping page turner ex agent run employers ca...\n",
       "6233    refreshing radiant love story read year lisa k...\n",
       "6234    frostfire amanda hocking stunning installment ...\n",
       "6235    years ago sam capra watched brother danny exec...\n",
       "Name: SynopsisKeywords, Length: 6236, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backup.apply(lambda x: ' '.join(x)).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TF-IDF Vectorizer for Keywords\n",
    "df['SynopsisKeywords'] = backup.apply(lambda x: ' '.join(x)).str.lower()\n",
    "\n",
    "tfidf_vectorizer_synopsis = TfidfVectorizer()\n",
    "tfidf_matrix_synopsis = tfidf_vectorizer_synopsis.fit_transform(df['SynopsisKeywords'])\n",
    "\n",
    "n_components = 50\n",
    "pca = PCA(n_components=n_components)\n",
    "tfidf_matrix_synopsis = pca.fit_transform(tfidf_matrix_synopsis.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords_df = keywords_df.copy()\n",
    "# keywords_df.fillna(0, inplace=True)\n",
    "# keywords_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use One-hot encoding for Author\n",
    "top_authors = df['Author'].value_counts().head(30).index.tolist()\n",
    "\n",
    "# Create new features for each of the top authors\n",
    "\n",
    "author_df = pd.DataFrame()\n",
    "\n",
    "for author in top_authors:\n",
    "    author_df[author] = (df['Author'] == author).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use One-hot encoding for Cover Types\n",
    "top_ctypes = df['CoverType'].value_counts().head(5).index.tolist()\n",
    "\n",
    "type_df = pd.DataFrame()\n",
    "\n",
    "# Create new features for each of the top authors\n",
    "for ctype in top_ctypes:\n",
    "    type_df[ctype] = (df['CoverType'] == author).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use One-hot encoding for BookCategory\n",
    "encoded_category = pd.get_dummies(df['BookCategory'], columns=['BookCategory'], prefix='BookCategory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all numerical features\n",
    "combined_features = pd.concat([\n",
    "    df[['Reviews', 'Ratings', 'Year', 'Polarity', 'Subjectivity', 'BookAge', 'ReviewImpact', 'RatingImpact']],\n",
    "    pd.DataFrame(tfidf_matrix_title),\n",
    "    pd.DataFrame(tfidf_matrix_synopsis),\n",
    "    encoded_category,\n",
    "    author_df,\n",
    "    type_df\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_features['RatingImpact'] = df['RatingImpact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_numeric(column):\n",
    "    return pd.to_numeric(column, errors='coerce')\n",
    "\n",
    "# combined_features = combined_features.apply(convert_to_numeric)\n",
    "combined_features.columns = combined_features.columns.astype(str)\n",
    "\n",
    "# combined_features.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Specify the columns you want to normalize\n",
    "columns_to_normalize = combined_features.columns.to_list()\n",
    "\n",
    "# Fit and transform the selected columns using Min-Max scaling\n",
    "combined_features[columns_to_normalize] = scaler.fit_transform(combined_features[columns_to_normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6236, 154)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb40e22d",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38821128",
   "metadata": {},
   "source": [
    "Do not change this part of the code only run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "627c0563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Trains a RandomForestRegressor model and evaluates its performance using the mean squared error (MSE).\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy.ndarray or pandas.DataFrame): The training data with (n_rows, n_features) shape.\n",
    "    y (numpy.ndarray or pandas.Series): The target variable (n_rows, 1) shape.\n",
    "\n",
    "    Returns:\n",
    "    float: The mean squared error (MSE) of the predictions(train data) made by the RandomForestRegressor.\n",
    "    float: The mean squared error (MSE) of the predictions(test data) made by the RandomForestRegressor.\n",
    "    \"\"\"\n",
    "    random_forest_regressor = RandomForestRegressor(criterion='squared_error')\n",
    "    random_forest_regressor.fit(X_train, y_train)\n",
    "    mse_train = random_forest_regressor.score(X_train, y_train)\n",
    "    \n",
    "    y_pred = random_forest_regressor.predict(X_test)\n",
    "\n",
    "    mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    return mse_train, mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(combined_features[:5270], df[:5270]['Price'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cfe38671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse_train, mse_test = train(X_train=X_train , y_train=y_train , X_test=X_test , y_test=y_test)\n",
    "# print(\"Train mse is: {} // Test mse is: {}\".format(mse_train,mse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Predict Prices based on test data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_regressor = RandomForestRegressor(criterion='squared_error')\n",
    "random_forest_regressor.fit(combined_features[:5699], df['Price'][:5699])\n",
    "prediction = random_forest_regressor.predict(combined_features[5699:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>483.34970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>750.15735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>355.95690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>466.56680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>564.49520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      Price\n",
       "0      0  483.34970\n",
       "1      1  750.15735\n",
       "2      2  355.95690\n",
       "3      3  466.56680\n",
       "4      4  564.49520"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df = pd.DataFrame(prediction).reset_index()\n",
    "prediction_df.rename(columns={0: 'Price'}, inplace=True)\n",
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.to_csv('Mahan Madani - Prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
